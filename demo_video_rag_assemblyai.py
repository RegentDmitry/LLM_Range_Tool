#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Demo script for Video RAG system with AssemblyAI
Shows advanced features: chapters, entities, topics, sentiment, speaker diarization
"""

import os
from pathlib import Path
from dotenv import load_dotenv
from lib.video_processor_assemblyai import VideoProcessorAssemblyAI
from lib.video_rag import VideoRAG

# Load .env file
load_dotenv()


def format_size(size_bytes):
    """Format file size in human readable format"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.2f} TB"


def check_video_file(file_path):
    """
    Check if video file is valid

    Returns:
        tuple: (is_valid, error_message)
    """
    path = Path(file_path)

    # Check if file exists
    if not path.exists():
        return False, f"File not found: {file_path}"

    # Get file size
    size_bytes = path.stat().st_size
    size_mb = size_bytes / (1024 * 1024)

    print(f"ğŸ“ File info:")
    print(f"   Name: {path.name}")
    print(f"   Size: {format_size(size_bytes)} ({size_mb:.2f} MB)")
    print(f"   Extension: {path.suffix}")
    print()

    # AssemblyAI supports larger files than Whisper
    if size_mb > 500:
        return False, f"File too large: {size_mb:.2f} MB (recommended max 500 MB)"

    # Check supported formats
    supported_formats = ['.mp4', '.mp3', '.wav', '.m4a', '.webm', '.mpeg', '.mpga', '.flac', '.ogg']
    if path.suffix.lower() not in supported_formats:
        return False, f"Unsupported format: {path.suffix}. Supported: {', '.join(supported_formats)}"

    return True, None


def display_advanced_features(transcript):
    """Display all advanced features from AssemblyAI"""

    # Chapters
    if transcript.chapters:
        print("\n" + "=" * 70)
        print(f"ğŸ“– AUTO CHAPTERS ({len(transcript.chapters)} chapters)")
        print("=" * 70)
        for i, chapter in enumerate(transcript.chapters[:5], 1):  # Show first 5
            print(f"\n[{i}] {chapter.headline}")
            print(f"    â±ï¸  {chapter.timestamp} - {chapter.duration:.0f}s")
            print(f"    ğŸ“ {chapter.summary[:150]}...")
        if len(transcript.chapters) > 5:
            print(f"\n... and {len(transcript.chapters) - 5} more chapters")

    # Topics
    if transcript.topics:
        print("\n" + "=" * 70)
        print(f"ğŸ·ï¸  TOPICS DETECTED ({len(transcript.topics)} topics)")
        print("=" * 70)
        top_topics = sorted(transcript.topics, key=lambda t: t.relevance, reverse=True)[:10]
        for topic in top_topics:
            print(f"   â€¢ {topic.topic}: {topic.relevance_percent}")

    # Entities
    if transcript.entities:
        print("\n" + "=" * 70)
        print(f"ğŸ¯ ENTITIES DETECTED ({len(transcript.entities)} entities)")
        print("=" * 70)
        # Group by type
        entities_by_type = {}
        for entity in transcript.entities:
            if entity.entity_type not in entities_by_type:
                entities_by_type[entity.entity_type] = []
            entities_by_type[entity.entity_type].append(entity.text)

        for entity_type, texts in entities_by_type.items():
            unique_texts = list(set(texts))[:5]  # Show up to 5 unique
            print(f"   {entity_type}: {', '.join(unique_texts)}")
            if len(unique_texts) > 5:
                print(f"      (+{len(set(texts)) - 5} more)")

    # Speakers
    if transcript.speakers:
        print("\n" + "=" * 70)
        print(f"ğŸ¤ SPEAKERS ({transcript.speaker_count} speakers)")
        print("=" * 70)
        # Show first utterance from each speaker
        seen_speakers = set()
        for speaker in transcript.speakers:
            if speaker.speaker not in seen_speakers:
                seen_speakers.add(speaker.speaker)
                print(f"\n   Speaker {speaker.speaker}:")
                print(f"      {speaker.text[:150]}...")
                print(f"      (Confidence: {speaker.confidence:.1%})")

    # Sentiment
    if transcript.sentiment_segments:
        print("\n" + "=" * 70)
        print(f"ğŸ˜Š SENTIMENT ANALYSIS")
        print("=" * 70)
        summary = transcript.sentiment_summary
        total = sum(summary.values())
        if total > 0:
            print(f"   ğŸ˜Š Positive: {summary['POSITIVE']} ({summary['POSITIVE']/total:.1%})")
            print(f"   ğŸ˜ Neutral:  {summary['NEUTRAL']} ({summary['NEUTRAL']/total:.1%})")
            print(f"   ğŸ˜ Negative: {summary['NEGATIVE']} ({summary['NEGATIVE']/total:.1%})")

        # Show some examples
        print("\n   Sample sentiments:")
        for sent in transcript.sentiment_segments[:3]:
            print(f"      {sent.sentiment_emoji} {sent.sentiment} ({sent.confidence:.0%}): {sent.text[:100]}...")

    # Key phrases
    if transcript.key_phrases:
        print("\n" + "=" * 70)
        print(f"ğŸ”‘ KEY PHRASES ({len(transcript.key_phrases)} phrases)")
        print("=" * 70)
        top_phrases = sorted(transcript.key_phrases, key=lambda p: p.rank, reverse=True)[:10]
        for phrase in top_phrases:
            print(f"   â€¢ {phrase.text} (importance: {phrase.rank_percent}, count: {phrase.count})")


def main():
    """Main demonstration function"""

    print("=" * 70)
    print("ğŸ¬ Video RAG System - AssemblyAI Edition")
    print("=" * 70)
    print()
    print("âœ¨ Advanced Features:")
    print("   âœ“ Auto Chapters with summaries")
    print("   âœ“ Entity Detection (people, places, organizations)")
    print("   âœ“ Topic Detection (automatic categorization)")
    print("   âœ“ Sentiment Analysis (positive/negative/neutral)")
    print("   âœ“ Speaker Diarization (who said what)")
    print("   âœ“ Key Phrases (important highlights)")
    print()

    # Check API keys
    openai_key = os.getenv('OPENAI_API_KEY')
    assemblyai_key = os.getenv('ASSEMBLYAI_API_KEY')

    if not assemblyai_key:
        print("âŒ ASSEMBLYAI_API_KEY not found in .env file")
        print("   Add your AssemblyAI API key to .env:")
        print("   ASSEMBLYAI_API_KEY=your-key-here")
        print()
        print("ğŸ’¡ Get your API key at: https://www.assemblyai.com/")
        return

    if not openai_key:
        print("âš ï¸  OPENAI_API_KEY not found (needed for embeddings)")
        print("   Add your OpenAI API key to .env:")
        print("   OPENAI_API_KEY=sk-your-key-here")
        print()

    print(f"âœ“ AssemblyAI API key found: {assemblyai_key[:20]}...")
    if openai_key:
        print(f"âœ“ OpenAI API key found: {openai_key[:20]}...")
    print()

    # ==================================================================
    # STEP 1: Transcribe video with AssemblyAI
    # ==================================================================
    print("=" * 70)
    print("ğŸ“ STEP 1: Video Transcription with AssemblyAI")
    print("=" * 70)
    print()

    test_video_path = input("Enter path to video file (or Enter to skip): ").strip()

    if not test_video_path:
        print("âš ï¸  Video file not specified")
        print()
        print("ğŸ’¡ Usage example:")
        print("   1. Download a poker tutorial video (AssemblyAI supports up to 500MB)")
        print("   2. Run the script again and provide the file path")
        print()
        print("ğŸ“š What this script does:")
        print("   âœ“ Transcribes video via AssemblyAI API")
        print("   âœ“ Generates auto chapters with summaries")
        print("   âœ“ Detects entities, topics, sentiment")
        print("   âœ“ Identifies speakers (if multiple people)")
        print("   âœ“ Saves enhanced transcript to JSON")
        print("   âœ“ Indexes to ChromaDB for semantic search")
        print()
        return

    # Check video file
    is_valid, error_msg = check_video_file(test_video_path)
    if not is_valid:
        print(f"âŒ {error_msg}")
        return

    # Initialize processor
    print("ğŸ”§ Initializing AssemblyAI processor...")
    processor = VideoProcessorAssemblyAI(assemblyai_api_key=assemblyai_key)
    print()

    # Transcribe
    print("ğŸ¤ Starting transcription with AssemblyAI...")
    print("   This will take a few minutes...")
    print()

    try:
        transcript, chunks = processor.process_video(
            video_path=test_video_path,
            video_id="test_video_assemblyai_001",
            title="Test poker tutorial video (AssemblyAI)",
            url="https://example.com/video/001",
            language="en",  # Change to "ru" for Russian
            use_chapters=True  # Use chapter-based chunking
        )

        print()
        print("=" * 70)
        print(f"âœ… Transcription completed successfully!")
        print("=" * 70)
        print()

        # Display advanced features
        display_advanced_features(transcript)

        # Save to JSON
        print()
        print("=" * 70)
        print("ğŸ’¾ Saving enhanced transcript to JSON...")
        print("=" * 70)
        try:
            json_path = processor.save_transcript_to_json(transcript, chunks)
            print(f"âœ“ Saved to: {json_path}")
        except Exception as e:
            print(f"âš ï¸  Warning: Could not save JSON: {e}")

    except Exception as e:
        print()
        print("=" * 70)
        print(f"âŒ Transcription error")
        print("=" * 70)
        print(f"Error: {str(e)}")
        print()

        error_str = str(e).lower()
        if "401" in error_str or "authentication" in error_str:
            print("ğŸ’¡ API key issue:")
            print("   Check your ASSEMBLYAI_API_KEY in .env file")
        elif "429" in error_str or "rate" in error_str:
            print("ğŸ’¡ Rate limit reached:")
            print("   Wait a few minutes and try again")
        elif "insufficient" in error_str or "quota" in error_str:
            print("ğŸ’¡ Insufficient credits:")
            print("   Add credits to your AssemblyAI account")

        print()
        return

    # ==================================================================
    # STEP 2: Index into vector DB (if OpenAI key available)
    # ==================================================================
    if not openai_key:
        print()
        print("âš ï¸  Skipping ChromaDB indexing (OpenAI API key needed for embeddings)")
        print("   Add OPENAI_API_KEY to .env to enable semantic search")
        return

    print()
    print("=" * 70)
    print("ğŸ—„ï¸  STEP 2: Index into ChromaDB")
    print("=" * 70)
    print()

    # Initialize RAG system
    print("ğŸ”§ Initializing ChromaDB...")
    rag = VideoRAG(
        openai_api_key=openai_key,
        collection_name="poker_videos_assemblyai",
        persist_directory="./chroma_db_assemblyai"
    )
    print()

    # Add chunks to DB
    print(f"ğŸ“¥ Adding {len(chunks)} enhanced chunks to vector database...")
    print()

    try:
        rag.add_chunks(chunks)
    except Exception as e:
        print(f"âŒ Error adding chunks: {e}")
        return

    # DB statistics
    stats = rag.get_stats()
    print()
    print("=" * 70)
    print("âœ… Indexing completed!")
    print("=" * 70)
    print()
    print(f"ğŸ“Š DB Statistics:")
    print(f"   Total chunks: {stats['total_chunks']}")
    print(f"   Unique videos: {stats['unique_videos']}")
    print()

    # ==================================================================
    # STEP 3: Interactive search
    # ==================================================================
    print("=" * 70)
    print("ğŸ” STEP 3: Semantic Search")
    print("=" * 70)
    print()
    print("ğŸ’¡ Try searching for:")
    print("   â€¢ Specific topics (e.g., 'preflop strategy')")
    print("   â€¢ Concepts (e.g., 'pot odds')")
    print("   â€¢ Players or names")
    print("   â€¢ Emotional content (will show sentiment)")
    print()
    print("Enter search query (or 'quit' to exit):")
    print()

    while True:
        try:
            user_query = input("Your query > ").strip()

            if user_query.lower() in ['quit', 'exit', 'q']:
                print("\nğŸ‘‹ Goodbye!")
                break

            if not user_query:
                continue

            print()
            results = rag.search(query=user_query, top_k=3)

            if not results:
                print("âŒ No results found\n")
            else:
                for i, result in enumerate(results, 1):
                    chunk = result.chunk
                    print(f"\n{'â”€' * 70}")
                    print(f"[{i}] {chunk.video_title}")
                    print(f"â±ï¸  {chunk.timestamp} | ğŸ“Š Relevance: {result.score:.1%}")

                    # Show chapter info if available
                    if hasattr(chunk, 'chapter_headline') and chunk.chapter_headline:
                        print(f"ğŸ“– Chapter: {chunk.chapter_headline}")

                    # Show entities if available
                    if hasattr(chunk, 'entities') and chunk.entities:
                        print(f"ğŸ¯ Entities: {', '.join(chunk.entities[:3])}")

                    # Show sentiment if available
                    if hasattr(chunk, 'dominant_sentiment') and chunk.dominant_sentiment:
                        emoji = {"POSITIVE": "ğŸ˜Š", "NEGATIVE": "ğŸ˜", "NEUTRAL": "ğŸ˜"}.get(chunk.dominant_sentiment, "")
                        print(f"{emoji} Sentiment: {chunk.dominant_sentiment}")

                    print(f"ğŸ”— {chunk.url_with_timestamp}")
                    print(f"ğŸ’¬ {chunk.text[:200]}...")
                    print()

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Goodbye!")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}\n")


if __name__ == "__main__":
    main()
